# AI-video-editing-tool

An AI-powered video keyframe processing tool that lets you:

- Extract keyframes from videos (using scene detection)
- Generate masks for objects using SAM (Segment Anything Model)
- Remove objects via inpainting
- Replace backgrounds using Stable Diffusion
- Composite keyframes into an AI-enhanced video
- Run all steps via CLI or a Streamlit UI

---

## Requirements

- Python 3.10 or 3.11
- A supported GPU (optional, but recommended for Stable Diffusion)
- Windows/macOS/Linux

Install dependencies:

```bash
pip install -r requirements.txt
````

---

## Core Features

| Phase | Description                                     |
| ----- | ----------------------------------------------- |
| 1ï¸   | Keyframe Extraction using scene detection       |
| 2ï¸   | SAM-based Mask Generation for each keyframe     |
| 3ï¸   | Object Removal using OpenCV inpainting          |
| 4ï¸   | AI Background Generation using Stable Diffusion |
| 5ï¸   | Composite Subject + New Background              |
| 6ï¸   | Rebuild final video from edited frames          |

---

## CLI Usage

```bash
python main.py --video path/to/video.mp4 --generate-masks --remove-mask --genai-bg "cyberpunk city at night" --make-video
```

### ğŸ”§ CLI Options

| Argument            | Description                                        |
| ------------------- | -------------------------------------------------- |
| `--video`           | Path to input video                                |
| `--out`             | Output folder for keyframes (default: `keyframes`) |
| `--threshold`       | Scene detection threshold (default: 30.0)          |
| `--generate-masks`  | Enable SAM-based mask generation                   |
| `--remove-mask`     | Inpaint masked regions from keyframes              |
| `--genai-bg PROMPT` | Generate AI background with prompt                 |
| `--make-video`      | Create final masked video                          |
| `--full-mask-video` | (Optional) Generate SAM masks for every frame      |

---

## Streamlit App

To run the UI:

```bash
streamlit run app.py
```

### Features:

* Upload a video
* Adjust keyframe threshold
* One-click mask generation and object removal
* Enter a text prompt for background generation
* Preview AI-composited frames

---

## Project Structure

```
roki/
â”‚
â”œâ”€â”€ app.py                   â† Streamlit app entrypoint
â”œâ”€â”€ main.py                  â† CLI entrypoint
â”œâ”€â”€ rokey_pipeline.py        â† Core orchestration logic
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ keyframes/               â† Extracted keyframes
â”œâ”€â”€ masks/                   â† SAM-generated masks
â”œâ”€â”€ removed/                 â† Inpainted keyframes
â”œâ”€â”€ output/                  â† Composite output & AI backgrounds
â”œâ”€â”€ video_input/             â† Uploaded videos
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_keyframes.py
â”‚   â”œâ”€â”€ generate_mask_sam.py
â”‚   â”œâ”€â”€ remove_mask.py
â”‚   â”œâ”€â”€ genai_background.py
â”‚   â”œâ”€â”€ full_video_mask.py
â”‚   â””â”€â”€ make_video_from_masks.py
```
## Screenshots

![mask](https://github.com/ashittis/rockey/blob/main/Screenshot%202025-07-11%20181445.png)
![keyframe](https://github.com/ashittis/rockey/blob/main/scene_1.jpg)
![Indexing](https://github.com/ashittis/rockey/blob/main/scene_1_mask.png)
![Chat](https://github.com/ashittis/rockey/blob/main/scene_1_removed.jpg)
![bgremove](https://github.com/ashittis/rockey/blob/main/scene_1_composite.jpg)

## Model Checkpoints

Make sure you place the following file in the root (or reference it):

* `sam_vit_b.pth` â€“ Pretrained SAM model checkpoint

---

## Example Prompt Ideas

* `"futuristic laboratory interior"`
* `"lush jungle with ancient ruins"`
* `"empty desert road at sunset"`
* `"cyberpunk alleyway with neon lights"`

---

## Credits

* [Segment Anything (Meta)](https://github.com/facebookresearch/segment-anything)
* [Stable Diffusion (Stability AI)](https://github.com/CompVis/stable-diffusion)
* [SceneDetect](https://pyscenedetect.readthedocs.io)

---
